# ============================
# detabase_to_gspread.py
# ============================
import pandas as pd
import numpy as np
import datetime
import os
from dateutil.relativedelta import relativedelta

from medal_rate_to_gspread import create_df_from_database, df_preprocessing, dataFrame_to_gspread
from utils import connect_to_spreadsheet
from logger_setup import setup_logger
from config import LOG_PATH, SPREADSHEET_IDS


logger = setup_logger("datebase_to_gspread", log_file=LOG_PATH)


# def dataFrame_to_gspread(df, spreadsheet, sheet_name):
#     today = datetime.date.today()
#     get_or_create_worksheet(spreadsheet, sheet_name, df.shape[0] + 5, df.shape[1] + 3)
#     sheet = spreadsheet.worksheet(sheet_name)
#     sheet.clear()
#     set_with_dataframe(sheet, df, include_index=True)
#     sheet.update_cell(1, 1, today.strftime("UPDATED: %Y-%m-%d"))
#     logger.info(f"ğŸ’¾ ã‚·ãƒ¼ãƒˆæ›´æ–°å®Œäº†: {sheet_name}")





def history_by_unit(df):
    merged_by_unit = pd.DataFrame()
    
    pivot_targets = ["medals", "game", "RB_rate", "Total_rate", "Grape_rate"]
    index_targets = ["area", "model_name", "unit_no"]
    columns_targets = ["date"]

    for model in df["model_name"].unique():
        
        # ãƒ¢ãƒ‡ãƒ«ã”ã¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        df_model = df[df["model_name"] == model]
        pivot_results = {}
        for col in pivot_targets:
            table = df_model.pivot_table(
                index=index_targets,
                columns=columns_targets,
                values=col,
                aggfunc="sum",
            )
            pivot_results[col] = table
        
        medals = pivot_results["medals"]
        game = pivot_results["game"]
        rb_rate = pivot_results["RB_rate"]
        total_rate = pivot_results["Total_rate"]
        grape_rate = pivot_results["Grape_rate"]
        medal_rate = ((medals + game * 3) / (game * 3)).round(3)
        
        # ãƒ©ãƒ³ã‚­ãƒ³ã‚°åˆ—ä½œæˆ
        rolling7 = medals.T.rolling(7, min_periods=7).sum().T
        medal_rank7 = rolling7.rank(method="min", ascending=True)
        medal_rank7 = medal_rank7.fillna(0).replace([np.inf, -np.inf], 0).astype(int)
        rolling5 = medals.T.rolling(5, min_periods=5).sum().T
        medal_rank5 = rolling5.rank(method="min", ascending=True)
        medal_rank5 = medal_rank5.fillna(0).replace([np.inf, -np.inf], 0).astype(int)
        rolling3 = medals.T.rolling(3, min_periods=3).sum().T
        medal_rank3 = rolling3.rank(method="min", ascending=True)
        medal_rank3 = medal_rank3.fillna(0).replace([np.inf, -np.inf], 0).astype(int)
        medal_rank1 = medals.rank(method="min", ascending=True)
        medal_rank1 = medal_rank1.fillna(0).replace([np.inf, -np.inf], 0).astype(int)

        # MultiIndexåŒ–ï¼ˆãƒ©ãƒ™ãƒ«ä»˜ã‘ï¼‰
        labeled_tables = [
            ("GRAPE_RATE", grape_rate),
            ("TOTAL_RATE", total_rate),
            ("RB_RATE", rb_rate),
            ("GAME", game),
            ("RATE_MEDAL", medal_rate),
            ("MEDALS", medals),
            ("3ROLLING", rolling3),
            ("5ROLLING", rolling5),
            ("7ROLLING", rolling7),
            ("1RANK", medal_rank1),
            ("3RANK", medal_rank3),
            ("5RANK", medal_rank5),
            ("7RANK", medal_rank7),
        ]
        for label, df_table in labeled_tables:
            df_table.columns = pd.MultiIndex.from_product([[label], df_table.columns])

        # åˆ—ã‚’äº¤äº’ã«æ•´åˆ—ã—ã¦çµ±åˆãƒ»NaNé™¤å»ãƒ»æ—¥ä»˜ã‚½ãƒ¼ãƒˆãƒ»ä¸€éƒ¨ãƒ‡ãƒ¼ã‚¿å‰Šé™¤
        interleaved_cols = [
            col
            for col_group in zip(*(df.columns for _, df in labeled_tables))
            for col in col_group
        ]
        merged = pd.concat([df for _, df in labeled_tables], axis=1)[interleaved_cols]
        merged = merged.iloc[:, ::-1]
        merged = merged[~merged.iloc[:, 7].isna()]

        # ã‚¨ãƒªã‚¢ã”ã¨ã«ç©ºè¡ŒæŒ¿å…¥ã—ã¦æ•´å½¢
        merged_by_area = pd.DataFrame()
        for area in merged.index.get_level_values("area").unique():
            area_merged = merged.xs(area, level="area", drop_level=False)
            if not area_merged.empty:
                empty_index = pd.MultiIndex.from_tuples(
                    [("", " ", " ")], names=merged.index.names
                )
                empty_row = pd.DataFrame(
                    [[""] * area_merged.shape[1]],
                    index=empty_index,
                    columns=area_merged.columns,
                )
                merged_by_area = pd.concat([merged_by_area, area_merged, empty_row])

        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å‰Šé™¤
        merged_by_area = merged_by_area.droplevel("area")
        
        if not merged_by_area.empty:
            empty_index = pd.MultiIndex.from_tuples(
                [(" ", " ")], names=merged_by_area.index.names
            )
            empty_row = pd.DataFrame(
                [[""] * merged_by_area.shape[1]],
                index=empty_index,
                columns=merged_by_area.columns,
            )
            merged_by_unit = pd.concat(
                [merged_by_unit, merged_by_area, empty_row], axis=0
            )

    # ç´¯è¨ˆã—ãŸæœ€å¾Œã®7æ—¥ã‚’å‰Šé™¤
    merged_by_unit = merged_by_unit.iloc[:, :-len(labeled_tables)*6]
    merged_by_unit.replace([np.inf, -np.inf], np.nan, inplace=True)
    
    return merged_by_unit





if __name__ == "__main__":
    
    HALL_LIST = [
        ("æ±äº¬éƒ½", "EXA FIRST", 1, 1),
        ("æ±äº¬éƒ½", "ã‚³ãƒ³ã‚µãƒ¼ãƒˆãƒ›ãƒ¼ãƒ«ã‚¨ãƒ•æˆå¢—", 1, 1),
        ("åŸ¼ç‰çœŒ", "ç¬¬ä¸€ãƒ—ãƒ©ã‚¶å‚æˆ¸1000", 1, 1),
        ("åŸ¼ç‰çœŒ", "ç¬¬ä¸€ãƒ—ãƒ©ã‚¶ç‹­å±±åº—", 1, 1),
        ("åŸ¼ç‰çœŒ", "ã¿ãšã»å°uno", 1, 1),
        ("åŸ¼ç‰çœŒ", "ç¬¬ä¸€ãƒ—ãƒ©ã‚¶ã¿ãšã»å°åº—", 1, 1),
    ]
    
    model_name = "ã‚¸ãƒ£ã‚°ãƒ©ãƒ¼"
    
    add_spreadsheet = False
    
    query = """
        -- å‡ºç‰ãƒ‡ãƒ¼ã‚¿ã«ãƒ›ãƒ¼ãƒ«åã¨æ©Ÿç¨®åã‚’çµåˆã—ã¦å–å¾—
        SELECT
            r.*, 
            h.name AS hall_name,     -- ãƒ›ãƒ¼ãƒ«åã‚’è¿½åŠ 
            m.name AS model_name     -- æ©Ÿç¨®åã‚’è¿½åŠ 
        FROM results r
        JOIN halls h ON r.hall_id = h.hall_id  -- ãƒ›ãƒ¼ãƒ«ã¨çµåˆ
        JOIN models m ON r.model_id = m.model_id  -- æ©Ÿç¨®ã¨çµåˆ
        WHERE h.name = ?  -- æŒ‡å®šãƒ›ãƒ¼ãƒ«ã®ã¿
        AND m.name LIKE '%ã‚¸ãƒ£ã‚°ãƒ©ãƒ¼%'  -- ã‚¸ãƒ£ã‚°ãƒ©ãƒ¼ç³»æ©Ÿç¨®ã«é™å®š
        ORDER BY r.date DESC, r.unit_no ASC;
        """
    
    for PREF, HALL_NAME, DAYS_AGO, PERIOD in HALL_LIST:
        if HALL_NAME not in SPREADSHEET_IDS:
            raise ValueError(f"{HALL_NAME} ã®ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆIDãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        SPREADSHEET_ID = SPREADSHEET_IDS[HALL_NAME]

        AREA_MAP_PATH = f"C:/python/dataOnline/anaslo_02/json/{HALL_NAME}_area_map.json"
        if not os.path.exists(AREA_MAP_PATH):
            AREA_MAP_PATH = f"C:/python/dataOnline/anaslo_02/json/other_area_map.json"

        today = datetime.date.today()
        start_date = datetime.date(today.year, today.month-1, 1) - relativedelta(days=6)
        df_db = create_df_from_database(HALL_NAME, start_date, today, model_name=model_name)
        df, model_list = df_preprocessing(df_db, HALL_NAME)

        # HISTORY ç”¨ã®ãƒ”ãƒœãƒƒãƒˆå‡¦ç†ãƒ»å‡ºåŠ›
        merged_by_unit = history_by_unit(df)
        merged_by_unit.to_csv(f"anaslo_02/out/{HALL_NAME}_history_by_unit.csv", index=True)
        
        if add_spreadsheet:
            spreadsheet = connect_to_spreadsheet(SPREADSHEET_ID)
            dataFrame_to_gspread(merged_by_unit, spreadsheet, sheet_name="HISTORY")
        
